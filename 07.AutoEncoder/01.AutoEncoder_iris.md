# Autoencoder on Iris Dataset 
* Source : https://www.kaggle.com/shivam1600/autoencoder-on-iris-dataset


```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
%matplotlib inline
```


```python
# Importing Data
!rm iris0.csv
![ ! -f iris0.csv ]&&wget https://raw.githubusercontent.com/Finfra/AI_Vision/master/data/iris0.csv


```


```python
data = pd.read_csv("iris0.csv")
data.head()
x_train, x_test, y_train, y_test = train_test_split(data[['Sepal.Length', 'Sepal.Width',
                                                          'Petal.Length', 'Petal.Width']],
                                                    data['Species'],test_size=0.1, random_state=1)
```


```python
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.optimizers import RMSprop

# this is the size of our encoded representations
encoding_dim1 = 6
encoding_dim2 = 4
encoding_dim3 = 2
input_dim = 4

# this is our input placeholder
input_img = Input(shape=(input_dim,))
# "encoded" is the encoded representation of the input
encoded = Dense(encoding_dim1)(input_img)
encoded = Dense(encoding_dim2)(encoded)
encoded = Dense(encoding_dim3)(encoded)

# "decoded" is the lossy reconstruction of the input
decoded = Dense(encoding_dim2)(encoded)
decoded = Dense(encoding_dim1)(decoded)
decoded = Dense(input_dim)(decoded)

# this model maps an input to its reconstruction
autoencoder = Model(input_img, decoded)


# this model maps an input to its encoded representation
encoder = Model(input_img, encoded)
#encoder = decoder_layer = autoencoder.layers[3]

# create a placeholder for an encoded (2-dimensional) input
encoded_input = Input(shape=(encoding_dim3,))
# retrieve the last layer of the autoencoder model

decoder_layer = autoencoder.layers[-3](encoded_input)
decoder_layer = autoencoder.layers[-2](decoder_layer)
decoder_layer = autoencoder.layers[-1](decoder_layer)

# create the decoder model
decoder = Model(encoded_input, decoder_layer)
opt=RMSprop(lr=0.001)
autoencoder.compile(loss='mean_squared_error', optimizer=opt)
autoencoder.summary()
```


```python
autoencoder.fit(x_train, x_train,
                epochs=333,
                batch_size=123,
                shuffle=True,
                validation_data=(x_test, x_test),
               callbacks=[])

# encode and decode some data points
# note that we take them from the *test* set
encoded_datapoints = encoder.predict(x_test)
decoded_datapoints = decoder.predict(encoded_datapoints)

print('Original Datapoints :')
print(x_test)
print('Reconstructed Datapoints :')
print(decoded_datapoints)
```

# Plotting Encoded Features


```python
encoded_dataset = encoder.predict(x_test[['Sepal.Length', 'Sepal.Width',
                                        'Petal.Length', 'Petal.Width']])
```

## Encode Dataset


```python
plt.rc('axes', unicode_minus=False)
plt.scatter(encoded_dataset[:,0], encoded_dataset[:,1], c=y_test.astype('category').cat.codes)
plt.show()
```

## Decoded Dataset(reconstruncted)


```python
decoded_dataset=decoder.predict(encoded_dataset)
plt.scatter(decoded_dataset[:,2], decoded_dataset[:,3], c=y_test.astype('category').cat.codes)
plt.show()
```

## Orignal Data


```python
plt.scatter(x_test['Petal.Length'], x_test['Petal.Width'],c=y_test.astype('category').cat.codes)
plt.show()
```


```python

```
