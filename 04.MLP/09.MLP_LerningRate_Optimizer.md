# 9. Learning Rate를 수정해 보고 싶다. 
* Learning Rate는 Optimizer에서 결정됨. 따라서 문자열 Parameter가 아닌 객체를 생성해서 적용해야 함. 
* [Optimizer 의 종류와 특성 (Momentum, RMSProp, Adam)](https://onevision.tistory.com/entry/Optimizer-의-종류와-특성-Momentum-RMSProp-Adam)
---
![](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F996A04425AB85ED0260F3E)

hyper parameter 설정


```
batch_size = 10
num_classes = 3
epochs = 200
```

라이브러리 및 함수 선언


```
import numpy as np
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt
def hist_view(hist):
  print('## training loss and acc ##')
  fig, loss_ax = plt.subplots()
  acc_ax = loss_ax.twinx()

  loss_ax.plot(hist.history['loss'], 'y', label='train loss')
  loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')

  loss_ax.set_xlabel('epoch')
  loss_ax.set_ylabel('loss')
  loss_ax.legend(loc='center')

  acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')
  acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')
  acc_ax.set_ylabel('accuracy')
  acc_ax.legend(loc='center right')

  plt.show()
```

데이터 로드


```
# from sklearn import datasets
# iris = datasets.load_iris()
# x=iris.data
import pandas as pd
![ ! -f  iris0.csv ]&&wget http://j.finfra.com/_file/iris0.csv
iris=pd.read_csv("iris0.csv")


```

input data 와 target data 설정


```
x=iris.iloc[:,0:4].values
y_text=iris.iloc[:,4:5]

sets=y_text.drop_duplicates()["Species"].tolist()
encoder={k:v for v,k in enumerate(sets)}
y_num=[ encoder[i] for i in y_text["Species"].tolist() ]



```

훈련 데이터와 평가 데이터 나누기


```
# iris.target → y
y= keras.utils.to_categorical(y_num, num_classes)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

```

모델 생성


```
model = Sequential()
model.add(Dense(6, activation='tanh', input_shape=(4,)))

model.add(Dense(4, activation=keras.activations.tanh))
model.add(Dense(num_classes, activation='softmax'))
model.summary()

```

## Optimizer 종류 확인
Keras 에서 사용 가능한 Optimizer 종류를 확인


```
from keras import optimizers
dir(optimizers)
```

## Learning Rate 수정
learning Rate 를 수정한 optimizer를 적용한다.


```
adam=optimizers.adam_v2.Adam(0.001)
model.compile(loss='categorical_crossentropy',
              optimizer=adam,
              metrics=['accuracy'])

```

Model 훈련


```
# batch_size,epochs
hist=model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=0,
          validation_data=(x_test, y_test))


```

## 결과 확인


```
hist_view(hist)
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

```


    
![png](09.MLP_LerningRate_Optimizer_files/09.MLP_LerningRate_Optimizer_20_0.png)
    


    Test loss: 0.1322030872106552
    Test accuracy: 0.9555555582046509



```
decoder = {k:v for k,v in enumerate( sets )}
decoder
```


```
r=np.argmax(model.predict(x_test[:10,:]), axis=-1)
[decoder[i] for i in r]
```

# 이제 Match Nomalization과 Dropout도 적용해 보자


```

```
