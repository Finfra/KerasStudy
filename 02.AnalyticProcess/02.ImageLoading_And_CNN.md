# ImageLoading And CNN
이미지를 로딩하는 법과 CNN 에 대해서 알아보겠습니다. 런타임이 GPU로 설정되었는지 꼭 확인하고 시작하시길 바랍니다.

## Imagemagick 설치
이미지를 다루는데 있어서 여러가지 툴 중에 추천드리는 프로그램입니다.


```bash
%%bash
apt install -y imagemagick

```

    
    WARNING: apt does not have a stable CLI interface. Use with caution in scripts.
    


## 예제 Image 다운로드
Flower 이미지를 다운로드합니다.


```bash
%%bash
[ ! -f flower_photos_300x200_small_train_test2.zip ]&& wget https://raw.githubusercontent.com/Finfra/AI_Vision/master/data/flower_photos_300x200_small_train_test2.zip

rm -rf __MACOSX
rm -rf flowers
unzip -q flower_photos_300x200_small_train_test2.zip
mv flower_photos_300x200_small_train_test2 flowers

cd flowers
# files=$(find |grep "\.jpg$\|\.png$")
# for i in $files; do
#     # convert $i -quiet  -resize 300x200^ -gravity center -extent 300x200  -colorspace Gray    ${i%.*}.png
#     convert $i -quiet  -resize 300x200^ -gravity center -extent 300x200  -define png:color-type=2   ${i%.*}.png

#     # identify ${i%.*}.png
#     rm -f $i
# done

find .|grep .DS_Store|xargs rm -f
find .|head -n 10
```

## Image Resize
Image 데이터의 경우 크기가 들쭉날쭉하게 들어오게 될 가능성이 높습니다. 그러므로 하나의 사이즈로 통일을 해주는 전처리 작업이 필요합니다.


```
from os import listdir
from os.path import isfile, join
import cv2
def getFolder(thePath,isFile=True):
  return [f for f in listdir(thePath) if isFile == isfile(join(thePath, f)) ]

def convert(thePath,to_w,to_h):
  print(thePath) # 향후 OpenCV로 이미지 변환하는 부분
  img=cv2.imread(thePath)
  img=cv2.resize(img,(to_w,to_h))
  cv2.imwrite(thePath,img)

def convertAll(tPath,to_w,to_h):
  for folder in getFolder(tPath,False):
    print('-',folder)
    convertAll(join(tPath,folder),to_w,to_h)
  for files in getFolder(tPath,True):
    convert(join(tPath,files),to_w,to_h)
w=300
h=200
convertAll('/content/flowers',w,h)

```

위의 작업 후 Image 를 확인해 보시면 300x200 사이즈로 잘 처리된 것을 확인하실 수 있습니다.


```
!identify /content/flowers/train/daisy/4286053334_a75541f20b_m.jpg

```

tip. 폴더 리스트와 파일리스트를 가져오는 법은 아래와 같습니다.


```
getFolder('/content/flowers/',False) # folder list
# getFolder('/content/flowers/test/daisy',True) # file list

```

위의 리사이즈 방법 예시를 좀 더 보기 편하게 포현을 해보면 아래와 같습니다.


```
# import os
# def convert(thePath,to_w,to_h):
#   print(thePath) # 향후 OpenCV로 이미지 변환하는 부분
#   img=cv2.imread(thePath)
#   img=cv2.resize(img,(to_w,to_h))
#   cv2.imwrite(thePath,img)

# img_list=[i for i in os.walk('/content/flowers')]

# for t in img_list:
#   path=t[0]
#   for f in t[2]:
#     print(join(path,f))
#     convert(join(path,f),400,300)


```

## ImageDataGenerator
ImageDataGenerator 를 통해 트레이닝, 테스트 데이터를 만들어 줄 수 있다. 


```
from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen=ImageDataGenerator()
```

flow_from_directory 라는 함수를 사용하여 폴더 형태로된 데이터 구조를 바로 가져와서 사용할 수 있다.


```
# help(datagen.flow_from_directory)
train_data=datagen.flow_from_directory(
    '/content/flowers/train',
    target_size=(h, w),
    batch_size=32,
    class_mode="categorical"
)
test_data=datagen.flow_from_directory(
    '/content/flowers/test',
    target_size=(h, w),
    batch_size=32,
    class_mode="categorical"
)
```

훈련 데이터를 확인해 보면 위에서 설정한 파라미터들이 들어간 것을 확인할 수 있다.


```
# dir(train_data)
len(set(train_data.classes))
```


```
train_data.classes[0]
```


```
train_data.filepaths[0]
```


```
train_data.image_shape
```

직접 이미지를 띄워서 보는 것도 가능하다<br>(ctrl+enter 로 실행하면 계속 다음 이미지를 확인해볼 수 있다.)



```
import matplotlib.pyplot as plt

images,labels=train_data.next()
# images[0]/255
plt.axis(False)
plt.imshow(images[0]/255)

```


    
![png](02.ImageLoading_And_CNN_files/02.ImageLoading_And_CNN_23_0.png)
    


## CNN 모델 만들기
위의 전처리 된 이미지를 가지고 훈련할 모델을 만들어 보자.


```
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import numpy as np
```


```
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(h,w, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(2, activation='softmax'))
model.summary()

```

훈련시키기


```
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
# dir(model)
#model.fit(train_images, train_labels, epochs=100,callbacks=[tensorboard_callback])
model.fit_generator(train_data, 
                    validation_data=test_data, 
                    validation_steps=8,
                    epochs=100
)
```

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
      warnings.warn('`Model.fit_generator` is deprecated and '


    6/6 [==============================] - ETA: 0s - loss: 431.5368 - accuracy: 0.4364WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.
    6/6 [==============================] - 5s 231ms/step - loss: 431.5368 - accuracy: 0.4364 - val_loss: 14.3570 - val_accuracy: 0.4857
    Epoch 2/100
    6/6 [==============================] - 0s 72ms/step - loss: 4.3865 - accuracy: 0.4970
    Epoch 3/100
    6/6 [==============================] - 0s 74ms/step - loss: 5.8834 - accuracy: 0.5030
    Epoch 4/100
    6/6 [==============================] - 0s 89ms/step - loss: 0.6890 - accuracy: 0.4970
    Epoch 5/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.7055 - accuracy: 0.4970
    Epoch 6/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6854 - accuracy: 0.4970
    Epoch 7/100
    6/6 [==============================] - 0s 74ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 8/100
    6/6 [==============================] - 0s 87ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 9/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 10/100
    6/6 [==============================] - 0s 83ms/step - loss: 0.6932 - accuracy: 0.5091
    Epoch 11/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 12/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 13/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 14/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 15/100
    6/6 [==============================] - 0s 74ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 16/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 17/100
    6/6 [==============================] - 0s 68ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 18/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 19/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 20/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 21/100
    6/6 [==============================] - 0s 67ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 22/100
    6/6 [==============================] - 0s 74ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 23/100
    6/6 [==============================] - 0s 67ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 24/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 25/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 26/100
    6/6 [==============================] - 0s 69ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 27/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 28/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 29/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 30/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 31/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 32/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 33/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 34/100
    6/6 [==============================] - 0s 83ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 35/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 36/100
    6/6 [==============================] - 0s 84ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 37/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 38/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 39/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 40/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 41/100
    6/6 [==============================] - 0s 83ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 42/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 43/100
    6/6 [==============================] - 0s 85ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 44/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 45/100
    6/6 [==============================] - 0s 84ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 46/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6931 - accuracy: 0.5030
    Epoch 47/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6932 - accuracy: 0.5030
    Epoch 48/100
    6/6 [==============================] - 0s 70ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 49/100
    6/6 [==============================] - 0s 68ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 50/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 51/100
    6/6 [==============================] - 0s 84ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 52/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 53/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 54/100
    6/6 [==============================] - 0s 88ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 55/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 56/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 57/100
    6/6 [==============================] - 0s 69ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 58/100
    6/6 [==============================] - 0s 73ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 59/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 60/100
    6/6 [==============================] - 0s 71ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 61/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 62/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 63/100
    6/6 [==============================] - 0s 87ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 64/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 65/100
    6/6 [==============================] - 0s 88ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 66/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 67/100
    6/6 [==============================] - 0s 74ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 68/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 69/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 70/100
    6/6 [==============================] - 1s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 71/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 72/100
    6/6 [==============================] - 0s 90ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 73/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 74/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 75/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 76/100
    6/6 [==============================] - 1s 77ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 77/100
    6/6 [==============================] - 0s 89ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 78/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 79/100
    6/6 [==============================] - 0s 90ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 80/100
    6/6 [==============================] - 0s 77ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 81/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 82/100
    6/6 [==============================] - 1s 77ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 83/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 84/100
    6/6 [==============================] - 1s 77ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 85/100
    6/6 [==============================] - 0s 78ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 86/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 87/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 88/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 89/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6933 - accuracy: 0.4970
    Epoch 90/100
    6/6 [==============================] - 0s 75ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 91/100
    6/6 [==============================] - 0s 89ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 92/100
    6/6 [==============================] - 1s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 93/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 94/100
    6/6 [==============================] - 0s 77ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 95/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 96/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 97/100
    6/6 [==============================] - 1s 78ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 98/100
    6/6 [==============================] - 0s 76ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 99/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970
    Epoch 100/100
    6/6 [==============================] - 0s 72ms/step - loss: 0.6932 - accuracy: 0.4970





    <tensorflow.python.keras.callbacks.History at 0x7effd200ce90>



위의 모델로 score 를 확인해 보자.


```
# score = model.evaluate(test_images, test_labels, verbose=0)
score = model.evaluate_generator(test_data,steps=60)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
```

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1973: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.
      warnings.warn('`Model.evaluate_generator` is deprecated and '


    Test loss: 0.6930501461029053
    Test accuracy: 0.5142857432365417



```
# cf) https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/
```


```

```
